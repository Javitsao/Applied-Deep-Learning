{\rtf1\ansi\ansicpg950\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww12720\viewh6820\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 CUDA_VISIBLE_DEVICES=4 python3 run_swag_no_trainer.py --train_file train_data.json --validation_file test_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size \'97gradient_accumulation_steps 2 --learning_rate 3e-5 --num_train_epochs 1 --model_name_or_path train_model\
\
CUDA_VISIBLE_DEVICES=2 python3 run_swag_no_trainer.py --train_file train_data.json --validation_file valid_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 1 --model_name_or_path train_model --debug\
\
cd /tmp2/b10902027/ADL/hw1/\
source /tmp2/b10902027/miniconda3/etc/profile.d/conda.sh\
conda activate adlhw1\
\
CUDA_VISIBLE_DEVICES=2 python3 run_qa_no_trainer.py --train_file train_data_2.json --validation_file test_data_2.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 1 --model_name_or_path hfl/chinese-bert-wwm-ext\
\
!python3 run_swag_no_trainer.py --train_file train_data.json --validation_file valid_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 2 --model_name_or_path hfl/chinese-bert-wwm-ext\
\
Transfer train test:\
python3 transfer_train.py\
python3 transfer_test.py\
\
CUDA_VISIBLE_DEVICES=2 python3 run_swag_no_trainer.py --train_file train_data.json --validation_file test_data.json --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3e-5 --num_train_epochs 1 --max_seq_length 512 --model_name_or_path bert-base-chinese\
\
Transfer train test:\
python3 transfer_train_2.py \
python3 transfer_test_2.py\
\
CUDA_VISIBLE_DEVICES=0 python3 run_qa_no_trainer.py --train_file train_data_2.json --validation_file test_data_2.json --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --gradient_accumulation_steps 2 --learning_rate 3e-5 --num_train_epochs 3 --max_seq_length 512 --model_name_or_path bert-base-chinese\
\
Transfer txt to csv:\
python3 txt_to_csv.py\
\
rm train_data.json test_data.json train_data_2.json test_data_2.json test_data_2_input\
\
!python3 run_swag_no_trainer.py --train_file train_data.json --validation_file test_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 1 --max_seq_length 512 --model_name_or_path bert-base-chinese\
\
0.968:\
!python3 run_swag_no_trainer.py --train_file train_data.json --validation_file valid_data.json --per_device_train_batch_size 4 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 1 --max_seq_length 512 --model_name_or_path shibing624/text2vec-base-chinese\
\
0.971:\
!python3 run_swag_no_trainer.py --train_file train_data.json --validation_file valid_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 1 --max_seq_length 512 --model_name_or_path shibing624/text2vec-base-chinese\
\
\
0.961:\
!python3 run_swag_no_trainer.py --train_file train_data.json --validation_file valid_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 1 --max_seq_length 512 --model_name_or_path bert-base-chinese\
\
\
CUDA_VISIBLE_DEVICES=6 python3 run_swag_no_trainer.py --train_file train_data.json --validation_file test_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 1e-5 --num_train_epochs 1 --max_seq_length 512 --model_name_or_path shibing624/text2vec-base-chinese --output_dir train_model\
\
CUDA_VISIBLE_DEVICES=0 python3 run_swag_no_trainer.py --train_file train_data.json --validation_file test_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 1 --max_seq_length 512 --model_name_or_path bert-base-chinese --output_dir p1_model_2\
\
CUDA_VISIBLE_DEVICES=0 python3 run_swag_no_trainer.py --train_file train_data.json --validation_file valid_data.json --per_device_train_batch_size 2 --per_device_eval_batch_size 1 --learning_rate 2e-5 --num_train_epochs 1 --max_seq_length 512 --model_name_or_path shibing624/text2vec-base-chinese --output_dir p1_model\
\
python3 run_qa_no_trainer.py --train_file train_data_2.json --validation_file valid_data_2.json --per_device_train_batch_size 4 --per_device_eval_batch_size 1 --learning_rate 1e-5 --num_train_epochs 1 --max_seq_length 512 --tokenizer_name nop --config_name nop\
}